'''
This code performs a variety of machine learning classification models on the
project dataset generated by the parsing & transformation code.  The classification
models used in this analysis include:  Decision Tree, Boosted Decision Tree,
Random Forest, K Nearest Neighbor, and Artificial Neural Network
'''

# Initial setup
# Import necessary libraries
import pandas as pd
import os
import numpy as np
import graphviz
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn import tree
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

# Set working directory (this directory should contain the dataset)
os.chdir('C:\\...\\directory path containing the dataset')

# Read in the dataset
data = pd.read_csv('dataset_flights.csv')

'''
Additions are made to the dataset based on observations from the data visualization
step.  Specifically, these additions are as follows:
    - Dummy variables indicating if aircraft category is JET or NOT JET
    - Dummy variables indicating whether the aircraft has 4 engines or not
    - Distance calculated as Airspeed multiplied by Flight Time
    - Dummy variables representing different blocks of arrival hours
    - Dummy variables representing different blocks of departure hours
'''

# Make additions to the dataset based on exploratory data analysis
data['jet'] = data['aircraft_cat'].apply(lambda x: 1 if x == 'JET' else 0)
data['not_jet'] = data['aircraft_cat'].apply(lambda x: 0 if x == 'JET' else 1)
data['four_eng'] = data['engine_num'].apply(lambda x: 1 if x == 'FOUR' else 0)
data['not_four_eng'] = data['engine_num'].apply(lambda x: 0 if x == 'FOUR' else 1)
data['distance'] = data['airspeed'] * data['flight_time'] / 60
data['arrhr_dev'] = data['arrive_hour'].apply(lambda x: 1 if x >= 4 and x <= 10 else 0)
data['arrhr_freq'] = data['arrive_hour'].apply(lambda x: 1 if x >= 12 and x <= 15 else 0)
data['arrhr_norm'] = 1 - (data['arrhr_dev'] + data['arrhr_freq'])
data['dephr_dev'] = data['depart_hour'].apply(lambda x: 1 if x >= 5 and x <= 8 else 0)
data['dephr_freq'] = data['depart_hour'].apply(lambda x: 1 if x >= 9 and x <= 10 else 0)
data['dephr_norm'] = 1 - (data['dephr_dev'] + data['dephr_freq'])

'''
Once appropriate data elements have been added to the dataset, then the specific
variables needed are pulled out of the dataset.  Some of those variables are then
categorized into dummy variables as appropriate.  The last step is to create data
structures for the predictive variables, categorical variable, and headers for
the predictive variables.
'''

# Filter dataset down to only the pertinent machine learning columns
data = data[['route_dev', 'flight_time', 'altitude', 'airspeed', 'distance'
             , 'origin', 'destination', 'storm', 'covid_flag', 'jet', 'not_jet'
             , 'four_eng', 'not_four_eng', 'arrhr_dev', 'arrhr_freq', 'arrhr_norm'
             , 'dephr_dev', 'dephr_freq', 'dephr_norm']]

# Create all necessary categorical dummy variable columns
data_cat = pd.get_dummies(data, columns = ['origin', 'destination', 'storm', 'covid_flag']
                            , prefix = ['orig', 'dest', 'wthr', 'cov'])

# Pull out the predictive and categorical variables from the data
pred_var = data_cat.iloc[:, 1:].values
cat_var = data_cat.iloc[:, 0].values
pred_headers = data_cat.columns[1:]


'''
Each model follows the same basic process:
    - Model classifier created as appropriate
    - K-Fold Cross-Validation performed on model classifier for average accuracy
    - Model classifier fit to dataset
    - Test sample randomly selected from the data
    - Confusion matrix generated accuracy calculations conducted
'''

# Decision Tree algorithm
# Set up Decision Tree classifier and perform cross-validation for accuracy
split = int(round(0.01 * len(pred_var), 0))
classifier_dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0,
                                    min_impurity_decrease = 0.0005,
                                    min_samples_split = split)
scores = cross_val_score(classifier_dt, pred_var, cat_var, cv = 10)
print('Mean Accuracy = ', '{:.2%}'.format(np.mean(scores)))

# Fit classifier
classifier_dt.fit(pred_var, cat_var)
# Split data into training and test sets & make predictions using test set
pred_train, pred_test, cat_train, cat_test = train_test_split(pred_var, cat_var
                                              , test_size = 0.25,random_state = 0)
cat_pred_dt = classifier_dt.predict(pred_test)

# Calculate confusion matrix on test set predictions
cm = confusion_matrix(cat_test, cat_pred_dt)
cm_columns = ['Freq Predict', 'Dev Predict']
cm_rows = ['Freq Actual', 'Dev Actual']
cm_df = pd.DataFrame(cm, columns = cm_columns, index = cm_rows)
print(cm_df)
print('\n')
print('Total Accuracy = ', '{:.2%}'.format(accuracy_score(cat_test, cat_pred_dt)))
print('True Freq Pred Rate = ', '{:.2%}'.format(cm[0, 0]/(cm[0, 0] + cm[0, 1])))
print('True Dev Pred Rate = ', '{:.2%}'.format(cm[1, 1] / (cm[1, 0] + cm[1, 1])))

'''
Building out the decision tree graphic is unique to the Decision Tree classification
model.  No other classification models perform this step.
'''

# Build out decision tree visual graphic
dot_data = tree.export_graphviz(classifier_dt, out_file = None,
                                feature_names = pred_headers, impurity = False
                                , proportion = True)
graph = graphviz.Source(dot_data)
graph.render('flight_tree', view = True)


# Boosted Decision Tree algorithm
# Import necessary library for Boosted Decision Tree
from sklearn.ensemble import AdaBoostClassifier

# Set up Boosted Decision Tree classifier and perform cross-validation for accuracy
classifier_boost = AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy',
                                                random_state = 0,
                                                min_impurity_decrease = 0.0005,
                                                min_samples_split = split),
                                                n_estimators = 50,
                                                learning_rate = 1.0)
scores = cross_val_score(classifier_boost, pred_var, cat_var, cv = 10)
print('Mean Accuracy = ', '{:.2%}'.format(np.mean(scores)))

# Fit classifier
classifier_boost.fit(pred_var, cat_var)
# Split data into training and test sets & make predictions using test set
pred_train, pred_test, cat_train, cat_test = train_test_split(pred_var, cat_var
                                              , test_size = 0.25,random_state = 0)
cat_pred_boost = classifier_boost.predict(pred_test)

# Calculate confusion matrix on test set predictions
cm = confusion_matrix(cat_test, cat_pred_boost)
cm_columns = ['Freq Predict', 'Dev Predict']
cm_rows = ['Freq Actual', 'Dev Actual']
cm_df = pd.DataFrame(cm, columns = cm_columns, index = cm_rows)
print(cm_df)
print('\n')
print('Total Accuracy = ', '{:.2%}'.format(accuracy_score(cat_test, cat_pred_boost)))
print('True Freq Pred Rate = ', '{:.2%}'.format(cm[0, 0]/(cm[0, 0] + cm[0, 1])))
print('True Dev Pred Rate = ', '{:.2%}'.format(cm[1, 1] / (cm[1, 0] + cm[1, 1])))


# Random Forest algorithm
# Import necessary libraries for Random Forest (includes scaler)
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# Scale the predictive data
scaler = StandardScaler()
scaler.fit(pred_var)
pred_var_scaled = scaler.transform(pred_var)

# Set up Random Forest classifier and perform cross-validation for accuracy
classifier_rf = RandomForestClassifier(n_estimators = 100, criterion = 'entropy'
                                       , random_state = 0
                                       , min_impurity_decrease = 0.0005
                                       , min_samples_split = split)
scores = cross_val_score(classifier_rf, pred_var_scaled, cat_var, cv = 10)
print('Mean Accuracy = ', '{:.2%}'.format(np.mean(scores)))

# Fit classifier
classifier_rf.fit(pred_var_scaled, cat_var)
# Split data into training and test sets
pred_train, pred_test, cat_train, cat_test = train_test_split(pred_var, cat_var
                                              , test_size = 0.25,random_state = 0)
# Scale the pred_test variables
scaler = StandardScaler()
scaler.fit(pred_test)
pred_test_scaled = scaler.transform(pred_test)
# Make predictions using scaled test set
cat_pred_rf = classifier_rf.predict(pred_test_scaled)

# Calculate confusion matrix on test set predictions
cm = confusion_matrix(cat_test, cat_pred_rf)
cm_columns = ['Freq Predict', 'Dev Predict']
cm_rows = ['Freq Actual', 'Dev Actual']
cm_df = pd.DataFrame(cm, columns = cm_columns, index = cm_rows)
print(cm_df)
print('\n')
print('Total Accuracy = ', '{:.2%}'.format(accuracy_score(cat_test, cat_pred_rf)))
print('True Freq Pred Rate = ', '{:.2%}'.format(cm[0, 0]/(cm[0, 0] + cm[0, 1])))
print('True Dev Pred Rate = ', '{:.2%}'.format(cm[1, 1] / (cm[1, 0] + cm[1, 1])))


# K Nearest Neighbor (KNN) algorithm
# Import necessary library for KNN
from sklearn.neighbors import KNeighborsClassifier

# Set up KNN classifier and perform cross-validation for accuracy
classifier_knn = KNeighborsClassifier(n_neighbors = 10, metric = 'minkowski')
scores = cross_val_score(classifier_knn, pred_var, cat_var, cv = 10)
print('Mean Accuracy = ', '{:.2%}'.format(np.mean(scores)))

# Fit classifier
classifier_knn.fit(pred_var, cat_var)
# Split data into training and test sets & make predictions using test set
pred_train, pred_test, cat_train, cat_test = train_test_split(pred_var, cat_var
                                              , test_size = 0.25,random_state = 0)
cat_pred_knn = classifier_knn.predict(pred_test)

# Calculate confusion matrix on test set predictions
cm = confusion_matrix(cat_test, cat_pred_knn)
cm_columns = ['Freq Predict', 'Dev Predict']
cm_rows = ['Freq Actual', 'Dev Actual']
cm_df = pd.DataFrame(cm, columns = cm_columns, index = cm_rows)
print(cm_df)
print('\n')
print('Total Accuracy = ', '{:.2%}'.format(accuracy_score(cat_test, cat_pred_knn)))
print('True Freq Pred Rate = ', '{:.2%}'.format(cm[0, 0]/(cm[0, 0] + cm[0, 1])))
print('True Dev Pred Rate = ', '{:.2%}'.format(cm[1, 1] / (cm[1, 0] + cm[1, 1])))


# Artificial Neural Network (ANN) algorithm
# Import necessary library for ANN
from sklearn.neural_network import MLPClassifier

# Set up ANN classifier and perform cross-validation for accuracy
classifier_ann = MLPClassifier(hidden_layer_sizes = (100, 10)
                                , max_iter = 500
                                , random_state = 0)
scores = cross_val_score(classifier_ann, pred_var_scaled, cat_var, cv = 4)
print('Mean Accuracy = ', '{:.2%}'.format(np.mean(scores)))

# Fit classifier
classifier_ann.fit(pred_var_scaled, cat_var)
# Split data into training and test sets
pred_train, pred_test, cat_train, cat_test = train_test_split(pred_var, cat_var
                                              , test_size = 0.25,random_state = 0)
# Scale the pred_test variables
scaler = StandardScaler()
scaler.fit(pred_test)
pred_test_scaled = scaler.transform(pred_test)
# Make predictions using scaled test set
cat_pred_ann = classifier_ann.predict(pred_test_scaled)

# Calculate confusion matrix on test set predictions
cm = confusion_matrix(cat_test, cat_pred_ann)
cm_columns = ['Freq Predict', 'Dev Predict']
cm_rows = ['Freq Actual', 'Dev Actual']
cm_df = pd.DataFrame(cm, columns = cm_columns, index = cm_rows)
print(cm_df)
print('\n')
print('Total Accuracy = ', '{:.2%}'.format(accuracy_score(cat_test, cat_pred_ann)))
print('True Freq Pred Rate = ', '{:.2%}'.format(cm[0, 0]/(cm[0, 0] + cm[0, 1])))
print('True Dev Pred Rate = ', '{:.2%}'.format(cm[1, 1] / (cm[1, 0] + cm[1, 1])))

